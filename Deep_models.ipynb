{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecSeats\n",
    "\n",
    "## Deep component : CNN and CDNN Models\n",
    "\n",
    "Main file for running Convolutional Neural Network (CNN) and Convolutional/Deconvolutional Neural Network (CDNN) on Locational choice experiment data.\n",
    "\n",
    "**Author of the code:** Anon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import copy\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function from other files import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.data_loading import load_data_matrix\n",
    "from src.room_transformation import keep_left_seat\n",
    "from src.deep.traintest import TrainTest\n",
    "from src.utils import Params\n",
    "from src.model.cnn import *\n",
    "from src.model.autoencoder_cnn import *\n",
    "from src.visualisation.plot_example import * \n",
    "from src.deep.deep_utils import *\n",
    "from src.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File setting\n",
    "\n",
    "Changing the `IND_FILE` value allows to change the studied dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the file to study:\n",
    "IND_FILE = 0\n",
    "\n",
    "params_list = [\"study2.json\", #0\n",
    "               \"study4_CF_FC.json\", #1\n",
    "              ]\n",
    "\n",
    "path_data = \"./data/Blanchard/\"\n",
    "\n",
    "params_cnn = Params(\"src/model/parameters/params_cnn.json\")\n",
    "params_auto_cnn = Params(\"src/model/parameters/params_autoencoder_cnn.json\")\n",
    "params_file = Params(path_data + \"parameters/\" + params_list[IND_FILE])\n",
    "\n",
    "print(\"TRAINING : \", params_file.csv_train)\n",
    "print(\"TEST : \", params_file.csv_valid)\n",
    "print(\"ROOM SIZE : \", params_file.room_size)\n",
    "print(\"PADDING : \", params_file.padding)\n",
    "print(\"NO CHOICE OPTION : \", params_file.no_choice)\n",
    "print(\"PAIRS OF SEATS : \", params_file.is_couple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TRAINING SET :\n",
    "try:\n",
    "    trainloader_mat = torch.load(path_data+\"dataloader/\"+params_file.dataloader_train)\n",
    "except FileNotFoundError:\n",
    "    print(\"Creating the Dataloader for train file...\")\n",
    "    trainloader_mat = load_data_loader(path = path_data + params_file.csv_train, \n",
    "                                       file_params = params_file,\n",
    "                                       model_params = params_cnn,\n",
    "                                       shuffle = True,\n",
    "                                       augmentation = True,\n",
    "                                       verbose = True)\n",
    "    torch.save(trainloader_mat, path_data+\"dataloader/\"+params_file.dataloader_train)\n",
    "\n",
    "### VALIDATION SET :\n",
    "try:\n",
    "    validloader_mat = torch.load(path_data+\"dataloader/\"+params_file.dataloader_valid)\n",
    "except FileNotFoundError:\n",
    "    print(\"Creating the Dataloader for test file...\")\n",
    "    validloader_mat = load_data_loader(path = path_data + params_file.csv_valid, \n",
    "                                       file_params = params_file,\n",
    "                                       model_params = params_cnn,\n",
    "                                       shuffle = False,\n",
    "                                       augmentation = False,\n",
    "                                       verbose = True)\n",
    "\n",
    "    torch.save(validloader_mat, path_data+\"dataloader/\"+params_file.dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(trainloader_mat.dataset))\n",
    "print(len(validloader_mat.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "In the following cell, comment/uncomment CNN or AutoencoderCNN to choose between CNN and CDNN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CNN(room_size = params_file.room_size, \n",
    "            params = params_cnn)\n",
    "# model = AutoencoderCNN(room_size = params_file.room_size, \n",
    "#                        params = params_auto_cnn)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=params_cnn.lr_opt)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "def top_1_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=1)\n",
    "\n",
    "def top_3_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=3)\n",
    "\n",
    "def top_5_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=5)\n",
    "\n",
    "def top_10_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=10)\n",
    "\n",
    "\n",
    "eval_fns = [top_1_acc, top_5_acc, top_10_acc]\n",
    "\n",
    "train_test_model = TrainTest(model, trainloader_mat, validloader_mat, optimizer, loss_fn, eval_fns)\n",
    "\n",
    "history_cnn = train_test_model.train(patience=20, max_it=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_fns = [top_1_acc, top_5_acc, top_10_acc, torch_weighted_l1]\n",
    "train_test_model.eval_fns = eval_fns\n",
    "\n",
    "accuracies = train_test_model.evaluate()\n",
    "\n",
    "print(\"Performance for valid set (in %): \", accuracies[1])\n",
    "\n",
    "if params_file.is_couple:\n",
    "    \n",
    "    accuracies = train_test_model.evaluate_couple()\n",
    "    print(\"Performance for valid set (in %) with the new method: \", accuracies[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
