{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecSeats\n",
    "\n",
    "## RecSeats Implementation\n",
    "\n",
    "Main file for running the hybrid model on Locational choice experiment data.\n",
    "\n",
    "**Author of the code:** Anon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librairies import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import copy\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function from other files import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.preprocessing.data_loading import *\n",
    "from src.preprocessing.compute_features import Feature_Pipeline\n",
    "from src.utils import Params\n",
    "from src.deep.traintest import TrainTest\n",
    "from src.model.user_specific import *\n",
    "from src.model.hybrid import *\n",
    "from src.visualisation.plot_example import * \n",
    "from src.model.cnn import *\n",
    "from src.model.autoencoder_cnn import *\n",
    "from src.deep.deep_utils import *\n",
    "from src.metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File setting\n",
    "\n",
    "Changing the `IND_FILE` value allows to change the studied dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index of the file to study:\n",
    "IND_FILE = 0\n",
    "\n",
    "params_list = [\"study2.json\", #0\n",
    "               \"study4_CF_FC.json\", #1\n",
    "              ]\n",
    "\n",
    "path_data = \"./data/Blanchard/\"\n",
    "\n",
    "params_parametric = Params(\"src/model/parameters/params_user_specific.json\")\n",
    "params_cnn = Params(\"src/model/parameters/params_cnn.json\")\n",
    "params_auto_cnn = Params(\"src/model/parameters/params_autoencoder_cnn.json\")\n",
    "params_hybrid = Params(\"src/model/parameters/params_hybrid.json\")\n",
    "params_file = Params(path_data + \"parameters/\" + params_list[IND_FILE])\n",
    "\n",
    "print(\"TRAINING : \", params_file.csv_train)\n",
    "print(\"TEST : \", params_file.csv_valid)\n",
    "print(\"ROOM SIZE : \", params_file.room_size)\n",
    "print(\"PADDING : \", params_file.padding)\n",
    "print(\"PAIRS OF SEATS : \", params_file.is_couple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_inputs = np.load(path_data+\"numpy/\"+params_file.dataloader_train+\"_inputs.npy\", allow_pickle=True)\n",
    "    train_outputs = np.load(path_data+\"numpy/\"+params_file.dataloader_train+\"_outputs.npy\", allow_pickle=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Creating data matrix for train set...\", end=\"\")\n",
    "    train_inputs, train_outputs = load_data_matrix(path = path_data + params_file.csv_train, \n",
    "                                                   room_size = params_file.room_size, \n",
    "                                                   padding = 0,\n",
    "                                                   verbose = False,\n",
    "                                                   to_tensor = 0,\n",
    "                                                   is_wso = params_file.is_wso\n",
    "                                                   )\n",
    "    np.save(path_data+\"numpy/\"+params_file.dataloader_train+\"_inputs.npy\", train_inputs)\n",
    "    np.save(path_data+\"numpy/\"+params_file.dataloader_train+\"_outputs.npy\", train_outputs)\n",
    "    print(\"Done.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    valid_inputs = np.load(path_data+\"numpy/\"+params_file.dataloader_valid+\"_inputs.npy\", allow_pickle=True)\n",
    "    valid_outputs = np.load(path_data+\"numpy/\"+params_file.dataloader_valid+\"_outputs.npy\", allow_pickle=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Creating data matrix for valid set...\", end=\"\")\n",
    "    valid_inputs, valid_outputs = load_data_matrix(path = path_data + params_file.csv_valid, \n",
    "                                                   room_size = params_file.room_size, \n",
    "                                                   padding = 0,\n",
    "                                                   verbose = False,\n",
    "                                                   to_tensor = 0,\n",
    "                                                   is_wso = params_file.is_wso\n",
    "                                                   )\n",
    "    np.save(path_data+\"numpy/\"+params_file.dataloader_valid+\"_inputs.npy\", valid_inputs)\n",
    "    np.save(path_data+\"numpy/\"+params_file.dataloader_valid+\"_outputs.npy\", valid_outputs)\n",
    "    print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file contains pairs of seats, then the transformation to predict the seat on the left is applied on the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params_file.is_couple:\n",
    "    for i in range(train_inputs.shape[0]):\n",
    "        for j in range(train_inputs.shape[1]):\n",
    "            train_inputs[i][j] = keep_left_seat(train_inputs[i][j])\n",
    "        for j in range(valid_inputs.shape[1]):\n",
    "            valid_inputs[i][j] = keep_left_seat(valid_inputs[i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_1_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=1)\n",
    "\n",
    "def top_3_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=3)\n",
    "\n",
    "def top_5_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=5)\n",
    "\n",
    "def top_10_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=10)\n",
    "\n",
    "def top_20_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=20)\n",
    "\n",
    "def top_100_acc(outputs, labels):\n",
    "    return torch_top_n_accuracy(outputs, labels, N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluation\n",
    "\n",
    "*Caution:* CNN or CDNN must be trained (on the same dataset) before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_1 = CNN(room_size = params_file.room_size, \n",
    "                         params = params_cnn)\n",
    "model_1.load_state_dict(torch.load(PATH_BEST_MODEL+\"CNN\"))\n",
    "\n",
    "# model_1 = AutoencoderCNN(room_size = params_file.room_size, \n",
    "#                        params = params_auto_cnn)\n",
    "# model_1.load_state_dict(torch.load(PATH_BEST_MODEL+\"Autoencoder_CNN\"))\n",
    "\n",
    "model_1 = model_1.to(device)\n",
    "\n",
    "\n",
    "pipeline = Feature_Pipeline(params_parametric)\n",
    "model_2 = Recommendation(params_parametric, pipeline)\n",
    "\n",
    "\n",
    "Content_model = ContentPart(room_size = params_file.room_size,\n",
    "                            padding = params_file.padding,\n",
    "                            cnn_model = model_1)\n",
    "\n",
    "User_model = UserPart(room_size = params_file.room_size,\n",
    "                      padding = params_file.padding,\n",
    "                      user_model = model_2)\n",
    "\n",
    "# eval_fns = [top_1_acc, top_3_acc, top_5_acc]\n",
    "eval_fns = [top_1_acc, top_3_acc, top_5_acc, torch_weighted_l1]\n",
    "\n",
    "verbose = False\n",
    "\n",
    "results = []          \n",
    "\n",
    "# for id_client in range(train_inputs.shape[0]):\n",
    "for id_client in range(40):\n",
    "\n",
    "    model = Hybrid(room_size = params_file.room_size,\n",
    "                   padding = params_file.padding,\n",
    "                   init_value = params_hybrid.init_value,\n",
    "                   content_model = Content_model,\n",
    "                   user_model = User_model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), \n",
    "                                lr=params_hybrid.lr_opt,\n",
    "                                momentum=params_hybrid.momentum, \n",
    "                                weight_decay=params_hybrid.weight_decay,\n",
    "                                nesterov=bool(params_hybrid.nesterov))\n",
    "\n",
    "    loss_fn = nn.NLLLoss()\n",
    "\n",
    "    if verbose:\n",
    "        print(\"################ Client nÂ°{} : ################\".format(id_client+1))\n",
    "\n",
    "\n",
    "    train_X, valid_X, train_Y, valid_Y = train_test_split(train_inputs[id_client], \n",
    "                                                          train_outputs[id_client], \n",
    "                                                          test_size=0.3, \n",
    "                                                          random_state=15)\n",
    "\n",
    "    test_X, test_Y = valid_inputs[id_client], valid_outputs[id_client]\n",
    "\n",
    "    train_X_f, train_Y_f = model_2.pipeline.compute_feature(train_X, train_Y)\n",
    "    model_2.fit(train_X_f, train_Y_f)\n",
    "\n",
    "\n",
    "    trainloader_mat = load_data_hybrid(valid_X, valid_Y, \n",
    "                                       room_size = params_file.room_size,\n",
    "                                       padding = params_file.padding,\n",
    "                                       params = params_hybrid)\n",
    "\n",
    "    validloader_mat = load_data_hybrid(test_X, test_Y, \n",
    "                                       room_size = params_file.room_size,\n",
    "                                       padding = params_file.padding,\n",
    "                                       params = params_hybrid)\n",
    "\n",
    "    train_test_model = TrainTest(model, trainloader_mat, validloader_mat, optimizer, \n",
    "                                 loss_fn, eval_fns, two_inputs = True)\n",
    "    history_cnn = train_test_model.train(patience = 20, max_it = 100, verbose = verbose) \n",
    "\n",
    "    acc = train_test_model.evaluate()[1]\n",
    "    results.append(acc)\n",
    "\n",
    "    if verbose:\n",
    "        a = model.alpha.item()\n",
    "        print(\"\\nAlpha Value : {:5.2%}\".format(a))\n",
    "        print(\"\\nFINAL VALID ACCURACY (Client {}) :\".format(id_client+1))\n",
    "        print(\"     Top1 : {:5.2%}\\n     Top3 : {:5.2%}\\n     Top5 : {:5.2%}\".format(acc[0], acc[1], acc[2]))\n",
    "        print(\"#\"*46+\"\\n\")\n",
    "    else:\n",
    "        print(\"\\r{}/{}\".format(id_client+1, train_inputs.shape[0]), end=\"\")   \n",
    "\n",
    "m = [np.nanmean(np.transpose(results)[i]) for i in range(len(eval_fns))]\n",
    "\n",
    "print(\"\\nFINAL MEAN OF VALID ACCURACY :\".format(id_client+1))\n",
    "print(\"     Top1 : {:5.2%}\\n     Top3 : {:5.2%}\\n     Top5 : {:5.2%}\".format(m[0], m[1], m[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
